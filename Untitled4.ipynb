{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install plotly && pip install dash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install dash==0.28.5  # The core dash backend\n",
    "! pip install dash-html-components==0.13.2  # HTML components\n",
    "! pip install dash-core-components==0.36.0  # Supercharged components\n",
    "! pip install dash-table==3.1.2  # Interactive DataTable component (new!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output\n",
    "from sklearn.externals import joblib\n",
    "import plotly.graph_objs as go\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objs as go\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from textblob import TextBlob\n",
    "from collections import Counter\n",
    "\n",
    "from newsapi import NewsApiClient\n",
    "\n",
    "from datetime import date, timedelta\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Este código é bo código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "yesterday = str(date.today()- timedelta(1))\n",
    "today = str(date.today())\n",
    "all_articles = newsapi.get_everything(sources= 'cnn',\n",
    "                                          from_param= yesterday,\n",
    "                                          to= today,\n",
    "                                          language='en',\n",
    "                                          sort_by='publishedAt')\n",
    "                                          #page=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2018-11-12'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "today = str(date.today()- timedelta(1))\n",
    "today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:8050/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [15/Nov/2018 20:46:41] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Nov/2018 20:46:47] \"GET /_dash-layout HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Nov/2018 20:46:47] \"GET /_dash-dependencies HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Nov/2018 20:46:47] \"GET /_favicon.ico HTTP/1.1\" 200 -\n",
      "[2018-11-15 20:46:47,686] ERROR in app: Exception on /_dash-update-component [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dsc/anaconda3/lib/python3.6/site-packages/flask/app.py\", line 1982, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"/home/dsc/anaconda3/lib/python3.6/site-packages/flask/app.py\", line 1614, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"/home/dsc/anaconda3/lib/python3.6/site-packages/flask/app.py\", line 1517, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"/home/dsc/anaconda3/lib/python3.6/site-packages/flask/_compat.py\", line 33, in reraise\n",
      "    raise value\n",
      "  File \"/home/dsc/anaconda3/lib/python3.6/site-packages/flask/app.py\", line 1612, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"/home/dsc/anaconda3/lib/python3.6/site-packages/flask/app.py\", line 1598, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"/home/dsc/anaconda3/lib/python3.6/site-packages/dash/dash.py\", line 918, in dispatch\n",
      "    return self.callback_map[target_id]['callback'](*args)\n",
      "  File \"/home/dsc/anaconda3/lib/python3.6/site-packages/dash/dash.py\", line 858, in add_context\n",
      "    output_value = func(*args, **kwargs)\n",
      "  File \"<ipython-input-3-ad387861be95>\", line 38, in get_news_today\n",
      "    language='en')\n",
      "  File \"/home/dsc/anaconda3/lib/python3.6/site-packages/newsapi/newsapi_client.py\", line 252, in get_everything\n",
      "    raise NewsAPIException(r.json())\n",
      "newsapi.newsapi_exception.NewsAPIException: {'status': 'error', 'code': 'parametersMissing', 'message': 'Required parameters are missing, the scope of your search is too broad. Please set any of the following required parameters and try again: q, sources, domains.'}\n",
      "127.0.0.1 - - [15/Nov/2018 20:46:47] \"POST /_dash-update-component HTTP/1.1\" 500 -\n",
      "127.0.0.1 - - [15/Nov/2018 20:47:24] \"POST /_dash-update-component HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "file=pd.read_csv('./data/dataset_news.csv', sep=',')\n",
    "newsapi = NewsApiClient(api_key='9fe0d6dd387c40bc8cb5fdec346f0bda')\n",
    "news_sources = newsapi.get_sources()\n",
    "yesterday = str(date.today()- timedelta(1))\n",
    "today = str(date.today())\n",
    "\n",
    "app = dash.Dash()\n",
    "\n",
    "app.layout = html.Div(children=[\n",
    "        html.H1(children='News Classifier', style={'textAlign':'center'}),\n",
    "    \n",
    "        html.Div(children=[\n",
    "                html.Label('What the chosen media organization is talking about?')], style={'textAlign': 'center'}),\n",
    "                html.Div(id='space', style={'padding': 10}),\n",
    "                dcc.Markdown('**Choose a media organization:**'),\n",
    "                dcc.Dropdown(\n",
    "                id='drop-down-media-source',\n",
    "                options=[{'label': i, 'value': i} \n",
    "                for i in list(map(lambda x: x['id'], filter(lambda x: x['language']=='en', news_sources['sources'])))]\n",
    "                ),\n",
    "                html.Div(id='space1', style={'padding': 10}),\n",
    "                dcc.Markdown('''**A Graph which classifies the news of the chosen media.\n",
    "                Therefore, we can see the main topics of the selected media from yesterday to today.**\n",
    "                NOTE: The graph takes a while to appear.'''),\n",
    "                dcc.Graph(id='bar_graph',style={'overflowY': 'scroll', 'height': 500})\n",
    "        ])\n",
    "\n",
    "@app.callback(\n",
    "    dash.dependencies.Output(component_id='bar_graph', component_property='figure'),\n",
    "    #[dash.dependencies.Input('button', 'n_clicks')],\n",
    "    [dash.dependencies.Input('drop-down-media-source', 'value')])\n",
    "\n",
    "\n",
    "def get_news_today( source_media):\n",
    "    all_articles = newsapi.get_everything(sources= source_media,\n",
    "                                          from_param= yesterday,\n",
    "                                          to= today,\n",
    "                                          language='en')\n",
    "    clean_text=[]\n",
    "    for text in all_articles['articles']:\n",
    "        #if the value of the ['content']key is a strig, it is putted in a new list (clean_text).\n",
    "        if type(text['content'])==str:\n",
    "            clean_text.append(text) \n",
    "    #-------------------------------------        \n",
    "    \n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit([\"business\", \"science and technology\", \"entertainment\", \"health\"])\n",
    "\n",
    "    x_axis=[]\n",
    "\n",
    "    corpus_business=''\n",
    "    corpus_sciencetechnology=''\n",
    "    corpus_entertainment=''\n",
    "    corpus_health=''\n",
    "    #Entrenamos o noso modelo\n",
    "    \n",
    "    vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit_transform(file['TITLE'])\n",
    "    encoder = LabelEncoder()\n",
    "    y = encoder.fit_transform(file['CATEGORY'])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    nb = MultinomialNB()\n",
    "    classifier_model = nb.fit(X_train, y_train)\n",
    "        \n",
    "    #Predecimos os valores dos textos. Non pode haber ningún None type porque senon a predicción non che da ben.\n",
    "    for i in range(len(clean_text)):\n",
    "        prediction = nb.predict(vectorizer.transform([clean_text[i]['content']]))\n",
    "        x_axis.append(list(le.inverse_transform(prediction)))\n",
    "        ##Metems os textos de cada categoria no coorpus de business, entertainment science/technology e health\n",
    "        if list(le.inverse_transform(prediction)) == ['entertainment']:\n",
    "            corpus_business= corpus_business + '' + clean_text[i]['content']\n",
    "        if list(le.inverse_transform(prediction)) == ['science and technology']:\n",
    "            corpus_sciencetechnology= corpus_sciencetechnology + '' + clean_text[i]['content']\n",
    "        if list(le.inverse_transform(prediction)) == ['entertainment']:\n",
    "            corpus_entertainment= corpus_entertainment + '' + clean_text[i]['content']\n",
    "        if list(le.inverse_transform(prediction)) == ['health']:\n",
    "            corpus_health= corpus_health + '' + clean_text[i]['content']\n",
    "\n",
    "    corpus=[corpus_business,corpus_sciencetechnology,corpus_entertainment,corpus_health]\n",
    "\n",
    "    #The data is going \n",
    "    x_axis_list=[]\n",
    "    for i in range(len(x_axis)):\n",
    "        x_axis_list.append(x_axis[i][0])\n",
    "    #Contamos as ocurrencias de cada tipo que aparece na base.\n",
    "    x=Counter(x_axis_list)\n",
    "\n",
    "    #NÚMERO DE NOTICIAS. de dnde son princialmente las noticias. Representamso os datos.\n",
    "    labels, values = zip(*Counter(x_axis_list).items())\n",
    "    \n",
    "    indexes = np.array([label for label in labels])\n",
    "    \n",
    "    return {'data': [go.Bar(\n",
    "            x= indexes,\n",
    "            y= values)],\n",
    "            'layout': go.Layout(\n",
    "            xaxis=dict(tickangle=-15))}\n",
    "\n",
    "app.css.append_css({'external_url': 'https://codepen.io/chriddyp/pen/bWLwgP.css'})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=False) \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
